{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from functools import reduce\n",
    "import os\n",
    "import pandas as pd  \n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## loaed images_train and preprocessing\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#load image train \n",
    "images_train = []\n",
    "for root, dirnames, i in os.walk(r\"C:\\Users\\Gabal\\Anaconda projects\\nile\\week 5\\train\\Train\"):\n",
    "    for i in range(2400):\n",
    "        filepath = os.path.join(root,str(i+1)+'.jpg')\n",
    "        image = cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "        images_train.append(image/255) \n",
    "#visulization images \n",
    "#index=1000\n",
    "#plt.imshow(images_train[index])\n",
    "#print('image dimention' ,images_train[index].shape ) \n",
    "#plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28) \n",
      "\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# convert all data to matrices to able to deal easliy with it to flatten and slicing and another operations .\n",
    "images_train = np.array(images_train, dtype=np.float32) \n",
    "# can me detect dtype or not \n",
    "print(images_train.shape,'\\n')\n",
    "\n",
    "images_flatten= images_train.reshape(2400,784)\n",
    "print(images_flatten[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# images_train division to  classes\n",
    "\n",
    "c0=images_flatten[0:240]\n",
    "c1=images_flatten[240:480]\n",
    "c2=images_flatten[480:720]\n",
    "c3=images_flatten[720:960]\n",
    "c4=images_flatten[960:1200]\n",
    "c5=images_flatten[1200:1440]\n",
    "c6=images_flatten[1440:1680]\n",
    "c7=images_flatten[1680:1920]\n",
    "c8=images_flatten[1920:2160]\n",
    "c9=images_flatten[2160:2400]\n",
    "classes=[c0,c1,c2,c3,c4,c5,c6,c7,c8,c9]\n",
    "#for i in range (10):\n",
    "    #print(classes[i].shape)\n",
    "    \n",
    "#clas=[]\n",
    "#for i in range(2400):\n",
    "#     for n in range(10):\n",
    "  #      clas.append(images_flatten.index(0,240)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[5]:\n",
    "#means\n",
    "m=[]\n",
    "for i in range (10):\n",
    "    m_clas = np.mean(classes[i], axis=0,keepdims=True)\n",
    "    #print(m[i].shape)\n",
    "    m.append(m_clas)\n",
    "  #  print(m[i].shape)\n",
    "\n",
    "#calculate all means minus each means and put it in list\n",
    "print(m[0].shape)\n",
    "all_means=sum(m)\n",
    "means_others=[]\n",
    "for i in range (len(m)):\n",
    "    mean=np.subtract((all_means),(m[i]))\n",
    "    means_others.append(mean/9)\n",
    "  #  print(means_others[i].shape)\n",
    "\n",
    "\n",
    "#all class minus each classe and put it in list\n",
    "class_others=[]\n",
    "all_classes=sum(classes)\n",
    "for i in range (len(classes)):\n",
    "    cls= [x for ind,x in enumerate(classes) if ind!=i] #np.subtract((all_classes),(classes[i]))\n",
    "    flattendedCls =[]\n",
    "    for c in cls:\n",
    "        for v in c:\n",
    "            flattendedCls.append(v)\n",
    "    class_others.append(flattendedCls)\n",
    "#all_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[ ]:\n",
    "# calculat sw\n",
    "sw=[]\n",
    "for n in range(10):\n",
    "    #for n in range(len(classes)):\n",
    "    res = np.zeros((784,784))\n",
    "    for cv in classes[n]:\n",
    "        s= np.subtract (cv , m[n]) \n",
    "        #print(s.shape)\n",
    "        ss= s.T\n",
    "        sw_one=np.dot(ss,s)\n",
    "        res += sw_one\n",
    "        #print(sw1.shape)\n",
    "    for cv in class_others[n]:  \n",
    "        c=np.subtract(cv,means_others[n])    #c=np.subtract((sum(classes,classes[n])),(sum(m,m[n])))\n",
    "        cc=c.T\n",
    "        sw_others= np.dot(cc,c)\n",
    "        res += sw_others\n",
    "    #sw + sw_all_class\n",
    "    #sw_n=sum(sw_one,sw_others)\n",
    "    sw.append(res)\n",
    "#for i in range (10):\n",
    " #   print(sw.shape)\n",
    "#print(sw.shape)\n",
    "#print(sw,'\\n','\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "(784, 784)\n"
     ]
    }
   ],
   "source": [
    "# In[22]:\n",
    "\n",
    "# inv. sW\n",
    "SW_inv =[]\n",
    "from numpy.linalg import pinv\n",
    "for i in range(len(sw)):\n",
    "    Sw=pinv(sw[i])\n",
    "    SW_inv.append(Sw) \n",
    "    \n",
    "# to visulizing lists shapes\n",
    "for i in range(len(sw)):\n",
    "    print(SW_inv[i].shape)\n",
    "#print(all_means[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## weights \n",
    "\n",
    "# In[23]:\n",
    "W=[] \n",
    "for i in range(10):\n",
    "    m_subtract =(np.subtract(means_others[i],m[i]))\n",
    "   # print(m_subtract .shape)\n",
    "    weight = np.dot((SW_inv[i]),m_subtract.T)\n",
    "    W.append(weight) \n",
    "#print(W)\n",
    "print(W[9].shape) \n",
    "# we have a list w0,w1,w2,w3,w4,w5,w6,w7,w8,w9\n",
    "\n",
    "# bais term \n",
    "# (W.T)(sum(m))/2\n",
    "# bais \n",
    "W0 =[]\n",
    "for i in range(10):\n",
    "    #b=(W[i].T)\n",
    "    #print(b.shape)\n",
    "   # bais=-(np.dot(all_means,b))//2\n",
    "    bais=-.5*(np.dot(sum(m[i],means_others[i]),W[i]))\n",
    "   # print(all_means.shape)\n",
    "   # print(bais.shape)\n",
    "    W0.append(bais)\n",
    "# to print all bais values \n",
    "#for c in range (10):\n",
    " #  print(W0[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28) \n",
      "\n",
      "(199, 1)\n",
      "(200, 784)\n"
     ]
    }
   ],
   "source": [
    "# ## Test images and preprocessing\n",
    "# In[24]:\n",
    "\n",
    "images_test= []\n",
    "for root, dirnames, i in os.walk(r\"C:\\Users\\Gabal\\Anaconda projects\\nile\\week 5\\train\\Test\"):\n",
    "    for i in range(200):\n",
    "            filepath = os.path.join(root, str(i+1)+'.jpg')\n",
    "            image = ndimage.imread(filepath)\n",
    "            images_test.append(image)\n",
    "#print(images_test)\n",
    "#convert images to arrays \n",
    "X = np.array(images_test) \n",
    "# can me detect dtype or not \n",
    "print(X.shape,'\\n')\n",
    "#read labels teast.\n",
    "t =pd.read_csv('Test Labels.txt')\n",
    "print(t.shape)\n",
    "#print(t.head(200))\n",
    "\n",
    "# flatten \n",
    "X=X.reshape(200,28*28)\n",
    "print(X.shape)\n",
    "#visulization images \n",
    "#index=100\n",
    "#plt.imshow(images_test[index])\n",
    "#plt.show()\n",
    "#print(images_test[index].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 2, 0, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 6, 8, 4, 4, 0, 9, 4, 4, 8, 8, 3, 4, 4, 8, 4, 9, 4, 4, 4, 2, 3, 5, 3, 5, 8, 9, 8, 5, 5, 9, 5, 5, 3, 5, 8, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 4, 8, 8, 8, 0, 3, 8, 3, 8, 8, 8, 3, 8, 8, 8, 9, 9, 8, 9, 8, 9, 9, 9, 7, 9, 9, 9, 7, 3, 9, 9, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## predict\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "predict=[]\n",
    "for j in range (len(t)):             #num of images \n",
    "    y_list=[]\n",
    "    for i in range (10):           #number of classes\n",
    "        y=(np.dot(X[j],W[i].flatten()))+W0[i]\n",
    "        y_list.append(y) \n",
    "        #for n in range(10):\n",
    "    c= np.amin(y_list)             \n",
    "    #print(c)                     \n",
    "    #print(y_list)               \n",
    "    #print(y_list.index(np.min(y_list)))    #print number of index\n",
    "    predict.append(y_list.index(min(y_list)))\n",
    "    #print((np.asarray(predict)).shape)\n",
    "print(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 1, 17,  0,  1,  0,  0,  0,  0,  1,  0],\n",
       "       [ 1,  1, 16,  1,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  1, 17,  0,  0,  0,  0,  2,  0],\n",
       "       [ 1,  0,  0,  2, 10,  0,  1,  0,  4,  2],\n",
       "       [ 0,  0,  1,  3,  0, 11,  0,  0,  3,  2],\n",
       "       [ 0,  0,  0,  0,  0,  1, 19,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  1, 18,  0,  0],\n",
       "       [ 1,  0,  0,  3,  1,  0,  0,  1, 14,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  3,  3, 13]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ## confution matrix and Accurcy\n",
    "\n",
    "# In[26]:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "array=confusion_matrix(t, predict)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.8844221106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[27]:\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(t, predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x186532f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[169]:\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(array, range(10),\n",
    "                  range(10))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}) # font size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
